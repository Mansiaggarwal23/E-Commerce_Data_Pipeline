

```markdown
# ğŸ›’ E-Commerce Data Pipeline

This project demonstrates a complete data engineering pipeline for an e-commerce business, integrating **Apache Airflow**, **DBT**, and **Snowflake** to automate the flow of data from raw CSVs to analytical models. It includes data orchestration, transformation, monitoring, and a foundation for business insights.

---

## ğŸ“¦ Project Components

### ğŸ”¹ 1. Airflow (Orchestration)
Located in the `airflow_project/` directory:
- DAGs for monitoring order delays
- Custom Python utilities for order checks
- Email alerting (configurable)
- Scheduling and pipeline automation

### ğŸ”¹ 2. DBT (Transformation)
Located in `dbt_ecommerce/`:
- Source staging for orders, customers, and shipments
- Data modeling with transformation logic
- Final marts (e.g., `order_status.sql`)
- Snapshots, tests, macros, and seeds setup for expansion

### ğŸ”¹ 3. Dummy Data Creation
In `dummy_data_creation/`:
- Jupyter notebook and CSVs for creating synthetic e-commerce data (`customers.csv`, `orders.csv`, `shipments.csv`)

---

## ğŸ—ƒï¸ Folder Structure

```

E-Commerce\_Data\_Pipeline/
â”‚
â”œâ”€â”€ airflow\_project/
â”‚   â”œâ”€â”€ airflow\.cfg
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â”œâ”€â”€ order\_monitor\_dag.py
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ check\_delayed\_orders.py
â”‚   â”‚       â””â”€â”€ config/
â”‚   â”‚           â””â”€â”€ snowflake\_config.yaml  # Ignored from Git
â”‚   â””â”€â”€ airflow\_venv/                      # Ignored from Git
â”‚
â”œâ”€â”€ dbt\_ecommerce/
â”‚   â””â”€â”€ ecommerce/
â”‚       â”œâ”€â”€ dbt\_project.yml
â”‚       â”œâ”€â”€ models/
â”‚       â”‚   â”œâ”€â”€ staging/
â”‚       â”‚   â”‚   â”œâ”€â”€ stg\_customers.sql
â”‚       â”‚   â”‚   â”œâ”€â”€ stg\_orders.sql
â”‚       â”‚   â”‚   â””â”€â”€ stg\_shipments.sql
â”‚       â”‚   â””â”€â”€ marts/
â”‚       â”‚       â””â”€â”€ order\_status.sql
â”‚       â”œâ”€â”€ macros/
â”‚       â”œâ”€â”€ seeds/
â”‚       â”œâ”€â”€ snapshots/
â”‚       â”œâ”€â”€ analyses/
â”‚       â””â”€â”€ tests/
â”‚
â”œâ”€â”€ dummy\_data\_creation/
â”‚   â”œâ”€â”€ dummy\_data\_creation.ipynb
â”‚   â”œâ”€â”€ customers.csv
â”‚   â”œâ”€â”€ orders.csv
â”‚   â””â”€â”€ shipments.csv
â”‚
â””â”€â”€ .gitignore

````

---

## ğŸ”§ Technologies Used

- **Apache Airflow** â€“ workflow orchestration
- **Python** â€“ utility scripts and data handling
- **DBT** â€“ SQL-based data transformation
- **Snowflake** â€“ target data warehouse
- **Jupyter Notebook** â€“ for data creation
- **Git & GitHub** â€“ version control

---

## ğŸš€ How to Run This Project

### 1. Clone the Repository
```bash
git clone https://github.com/Mansiaggarwal23/E-Commerce_Data_Pipeline.git
cd E-Commerce_Data_Pipeline
````

### 2. Set Up Virtual Environment

```bash
python -m venv airflow_venv
source airflow_venv/bin/activate   # On Windows: airflow_venv\Scripts\activate
pip install -r requirements.txt    # Make sure you have one or install manually
```

### 3. Configure Airflow

* Update `airflow.cfg` if needed
* Place your **Snowflake credentials** in `airflow_project/dags/utils/config/snowflake_config.yaml` (this file is excluded from Git)

### 4. Run Airflow

```bash
airflow db init
airflow webserver --port 8080
airflow scheduler
```

Visit `http://localhost:8080` to view and trigger DAGs.

### 5. Setup DBT

```bash
cd dbt_ecommerce/ecommerce/
dbt deps
dbt seed
dbt run
dbt test
```

Make sure your `~/.dbt/profiles.yml` is configured with your Snowflake credentials.

---

## ğŸ“ˆ Example Use Case

* Monitor delayed orders via Airflow DAG
* Transform raw order, customer, and shipment data
* Generate a mart table showing order statuses
* Alert the ops team via email if delays occur

---

## ğŸ“œ License

This project is intended for educational and demonstration purposes only.

---

## ğŸ™Œ Contributions

Feel free to fork the repository, submit pull requests, or open issues for feature suggestions or bugs.

---

## ğŸ”— Useful Links

* [Apache Airflow](https://airflow.apache.org/)
* [DBT Documentation](https://docs.getdbt.com/)
* [Snowflake Docs](https://docs.snowflake.com/)

```

---

Would you like:
- A badge section (e.g., Python version, Airflow status)?
- A live screenshot or flow diagram of your pipeline?

Let me know and Iâ€™ll enhance this further!
```
